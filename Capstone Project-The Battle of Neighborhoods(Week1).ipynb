{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Capstone Project-The Battle of Neighborhoods (Week1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction/Business Problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Greece attracts a lot of tourists for hiking cause of the number and beauty of her nature.\n",
    "\n",
    "The aim of this project is to recommend city destinations for mountain lovers in Greece.\n",
    "\n",
    "The first task would be to segment the cities based on their geographic distance (on km) from every mountain and cluster them based on that and as second step I will make another segmentation based on the similarity of the cities.\n",
    "\n",
    "After that I will merge them to filter the cities that are both similar and close to same montains.\n",
    "\n",
    "Finaly I will find the closest 5 mountains , based on their distance in km for every city in the final merged cluster and categorize them based on their height in 3 categories.\n",
    "\n",
    "I will make use of our data science tools to analyse data and focus on the relationship of cities and mountains in Greece."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will need two types of data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Wikipedia data for mountain informations like height , regional unit and coordinates.\n",
    "* Wikipedia data for cities informations like name , coordinates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Forsquare data about venues on every city in Greece."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I scrape the wikipedia data from https://en.wikipedia.org/wiki/List_of_mountains_in_Greece .\n",
    "\n",
    "I used **Scrapy** an open source and collaborative framework for extracting the data from websites. Here is my code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "import scrapy\n",
    "\n",
    "\n",
    "class MountainsSpider(scrapy.Spider):\n",
    "    name = 'mountains'\n",
    "    allowed_domains = ['en.wikipedia.org']\n",
    "    start_urls = ['http://en.wikipedia.org/wiki/List_of_mountains_in_Greece']\n",
    "\n",
    "    def parse(self, response):\n",
    "        table = response.xpath('//table[contains(@class,\"wikitable sortable\")]')\n",
    "        trs = table.xpath('.//tr')[2:]\n",
    "\n",
    "        for tr in trs:\n",
    "        \tpeak = tr.xpath('.//td[1]//text()').extract_first().strip()\n",
    "        \theight = tr.xpath('.//td[2]//text()').extract_first().strip()\n",
    "        \tmountain_range = tr.xpath('.//td[4]//text()').extract_first().strip()\n",
    "        \tregional_unit = tr.xpath('.//td[5]//text()').extract_first().strip()\n",
    "\n",
    "        \tnext_page_mountain_url = tr.xpath('.//td/a/@href').extract_first()\n",
    "        \tnext_page_region_url = tr.xpath('.//td[5]/a/@href').extract_first().strip()\n",
    "        \t\n",
    "        \tif next_page_mountain_url:\n",
    "        \t\tyield scrapy.Request(response.urljoin(next_page_mountain_url),\n",
    "    \t\t\t\t\t\t\t callback =self.parse_info,\n",
    "    \t\t\t\t\t\t\t meta={'peak': peak,\n",
    "    \t\t\t\t\t\t\t\t   'height': height,\n",
    "    \t\t\t\t\t\t\t\t   'mountain_range': mountain_range,\n",
    "    \t\t\t\t\t\t\t\t   'regional_unit':regional_unit})\n",
    "\n",
    "    def parse_info(self,response):\n",
    "        \tinfo = response.xpath('//table[contains(@class,\"infobox\")]')\n",
    "        \tlatitude = info.xpath('.//span[@class=\"latitude\"]/text()').extract_first()\n",
    "        \tlongitude = info.xpath('.//span[@class=\"longitude\"]/text()').extract_first()\n",
    "\n",
    "        \t# convert coordinates from DMS to dd\n",
    "        \tdef convert_coor(old_value):\n",
    "        \t\tdegrees = old_value.split('°')[0]\n",
    "        \t\tminutes = old_value.split('°')[1].split('′')[0]\n",
    "        \t\tseconds = old_value.split('°')[1].split('′')[1].split('″')[0]\n",
    "        \t\t#conversion formula\n",
    "        \t\tif(seconds.isnumeric()):\n",
    "        \t\t\tnew_value = float(degrees) + (float(minutes)/60) + (float(seconds)/3600)\n",
    "        \t\telse:\n",
    "        \t\t\tnew_value = float(degrees) + (float(minutes)/60)\n",
    "\n",
    "        \t\treturn(new_value)\n",
    "\n",
    "        \tif((latitude != \"\") & (longitude != \"\")):\n",
    "        \t\tmountain_latitude = convert_coor(latitude)\n",
    "        \t\tmountain_longitude = convert_coor(longitude)\n",
    "\n",
    "        \tpeak = response.meta['peak']\n",
    "        \theight = response.meta['height']\n",
    "        \tmountain_range = response.meta['mountain_range']\n",
    "        \tregional_unit = response.meta['regional_unit']\n",
    "\n",
    "        \tyield {\n",
    "        \t'peak':peak,\n",
    "        \t'height':height,\n",
    "        \t'mountain_range':mountain_range,\n",
    "        \t'regional_unit':regional_unit,\n",
    "        \t'mountain_latitude':mountain_latitude,\n",
    "        \t'mountain_longitude':mountain_longitude\n",
    "        \t}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I end up with a dataset that contains the **peak** , the **height** , the **mountain range** , the **coordinates** and the **regional unit** the mountain belongs.\n",
    "\n",
    "I follow a similar approach for the **regions** / **cities** . I got the **name** and the **coordinates** of the cities which is usefull to use this dataset in collaboration with the previous."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "import scrapy\n",
    "\n",
    "\n",
    "class RegionsSpider(scrapy.Spider):\n",
    "    name = 'regions'\n",
    "    allowed_domains = ['en.wikipedia.org']\n",
    "    start_urls = ['http://en.wikipedia.org/wiki/List_of_mountains_in_Greece']\n",
    "\n",
    "    def parse(self, response):\n",
    "        table = response.xpath('//table[contains(@class,\"wikitable sortable\")]')\n",
    "        trs = table.xpath('.//tr')[2:]\n",
    "\n",
    "        for tr in trs:\n",
    "        \tregional_unit = tr.xpath('.//td[5]//text()').extract_first().strip()\n",
    "\n",
    "        \tnext_page_region_url = tr.xpath('.//td[5]/a/@href').extract_first()\n",
    "        \t\n",
    "        \tif next_page_region_url:\n",
    "        \t\tyield scrapy.Request(response.urljoin(next_page_region_url),\n",
    "    \t\t\t\t\t\t\t callback =self.parse_info,\n",
    "    \t\t\t\t\t\t\t meta={'regional_unit':regional_unit})\n",
    "\n",
    "    def parse_info(self,response):\n",
    "        \tinfo = response.xpath('//table[contains(@class,\"infobox\")]')\n",
    "        \tlatitude = info.xpath('.//span[@class=\"latitude\"]/text()').extract_first()\n",
    "        \tlongitude = info.xpath('.//span[@class=\"longitude\"]/text()').extract_first()\n",
    "\n",
    "        \t# convert coordinates from DMS to dd\n",
    "        \tdef convert_coor(old_value):\n",
    "        \t\tdegrees = old_value.split('°')[0]\n",
    "        \t\tminutes = old_value.split('°')[1].split('′')[0]\n",
    "        \t\tseconds = old_value.split('°')[1].split('′')[1].split('″')[0]\n",
    "        \t\t#conversion formula\n",
    "        \t\tif(seconds.isnumeric()):\n",
    "        \t\t\tnew_value = float(degrees) + (float(minutes)/60) + (float(seconds)/3600)\n",
    "        \t\telse:\n",
    "        \t\t\tnew_value = float(degrees) + (float(minutes)/60)\n",
    "\n",
    "        \t\treturn(new_value)\n",
    "\n",
    "        \tif((latitude != \"\") & (longitude != \"\")):\n",
    "        \t\tmountain_latitude = convert_coor(latitude)\n",
    "        \t\tmountain_longitude = convert_coor(longitude)\n",
    "\n",
    "        \tregional_unit = response.meta['regional_unit']\n",
    "\n",
    "        \tyield {\n",
    "        \t'regional_unit':regional_unit,\n",
    "        \t'regional_latitude':mountain_latitude,\n",
    "        \t'regional_longitude':mountain_longitude\n",
    "        \t}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finaly I will use foursquare data about the near cities from each mountain to find venues in a given radius,  to separate them from each other. I will take the top 10 venues of every city. We will see at the end that cities having some specific similarities like islands cluster together."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
